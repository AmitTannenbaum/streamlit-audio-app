import streamlit as st
from google.cloud import speech
from pydub import AudioSegment
import os
import tempfile
import json

# ×”×’×“×¨×ª ×”×¨×©××•×ª Google Cloud
st.title("ğŸ™ï¸ ×ª××œ×•×œ ×•×—×™×ª×•×š ××•×“×™×•")

uploaded_auth_file = st.file_uploader("ğŸ“‚ ×”×¢×œ×” ×§×•×‘×¥ JSON ×©×œ ×”×¨×©××•×ª Google", type=["json"])
if uploaded_auth_file:
    with open("service_account.json", "wb") as f:
        f.write(uploaded_auth_file.read())
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "service_account.json"
    st.success("âœ… ×”×¨×©××•×ª × ×˜×¢× ×• ×‘×”×¦×œ×—×”!")

# ×”×¢×œ××ª ×§×•×‘×¥ ××•×“×™×•
uploaded_file = st.file_uploader("ğŸ“‚ ×”×¢×œ×” ×§×•×‘×¥ MP3", type=["mp3"])

if uploaded_file:
    # ×©××™×¨×ª ×”×§×•×‘×¥ ×©×”×•×¢×œ×” ×–×× ×™×ª
    temp_dir = tempfile.mkdtemp()
    input_audio_path = os.path.join(temp_dir, "uploaded.mp3")

    with open(input_audio_path, "wb") as f:
        f.write(uploaded_file.read())

    st.success("âœ… ×§×•×‘×¥ ×”×•×¢×œ×” ×‘×”×¦×œ×—×”!")

    # ×ª××œ×•×œ ×”×”×§×œ×˜×”
    def transcribe_audio(file_path):
        client = speech.SpeechClient()
        with open(file_path, "rb") as audio_file:
            audio_content = audio_file.read()

        audio = speech.RecognitionAudio(content=audio_content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.MP3,
            sample_rate_hertz=16000,
            language_code="en-US",
            enable_word_time_offsets=True  # ×–×× ×™ ×ª×—×™×œ×ª ××™×œ×™×
        )

        response = client.recognize(config=config, audio=audio)

        transcribed_text = []
        for result in response.results:
            for word_info in result.alternatives[0].words:
                word = word_info.word
                start_time = word_info.start_time.total_seconds()
                transcribed_text.append(f"{start_time:.2f} sec: {word}")

        return "\n".join(transcribed_text)

    # ×”×¨×¦×ª ×”×ª××œ×•×œ
    with st.spinner("â³ ××ª××œ×œ ××ª ×”×”×§×œ×˜×”..."):
        transcript = transcribe_audio(input_audio_path)

    st.subheader("ğŸ“œ ×ª××œ×•×œ ×¢× ×–×× ×™×:")
    st.text_area("ğŸ“– ×ª××œ×•×œ:", transcript, height=300)

    # ×‘×—×™×¨×ª ×˜×•×•×— ×œ×—×™×ª×•×š
    st.subheader("âœ‚ï¸ ×—×™×ª×•×š ×§×•×‘×¥ ××•×“×™×•:")
    start_time = st.number_input("â³ ×–××Ÿ ×”×ª×—×œ×” (×©× ×™×•×ª)", min_value=0.0, step=0.1)
    end_time = st.number_input("â³ ×–××Ÿ ×¡×™×•× (×©× ×™×•×ª)", min_value=0.0, step=0.1)

    # ×—×™×ª×•×š ×”××•×“×™×•
    if st.button("âœ‚ï¸ ×—×ª×•×š ×•×©××•×¨"):
        if end_time > start_time:
            cut_audio_path = os.path.join(temp_dir, "trimmed_audio.mp3")

            audio = AudioSegment.from_mp3(input_audio_path)
            cut_audio = audio[start_time * 1000:end_time * 1000]
            cut_audio.export(cut_audio_path, format="mp3")

            st.success("âœ… ×”×—×™×ª×•×š ×‘×•×¦×¢ ×‘×”×¦×œ×—×”!")

            # ×”×¦×’×ª × ×’×Ÿ ××•×“×™×•
            st.audio(cut_audio_path, format="audio/mp3")

            # ×§×™×©×•×¨ ×œ×”×•×¨×“×ª ×”×§×•×‘×¥
            with open(cut_audio_path, "rb") as f:
                st.download_button(label="ğŸ“¥ ×”×•×¨×“ ××ª ×”××•×“×™×• ×”×—×ª×•×š", data=f, file_name="trimmed_audio.mp3", mime="audio/mp3")
        else:
            st.error("âŒ ×–××Ÿ ×”×¡×™×•× ×—×™×™×‘ ×œ×”×™×•×ª ×’×“×•×œ ××–××Ÿ ×”×”×ª×—×œ×”!")
